[
    {
        "title": "A Deep Reinforcement Learning Approach for Ramp Metering Based on Traffic Video Data",
        "summary": "Ramp metering that uses traffic signals to regulate vehicle flows from the on-ramps has been widely implemented to improve vehicle mobility of the freeway. Previous studies generally update signal timings in real-time based on predefined traffic measures collected by point detectors, such as traffic volumes and occupancies. Comparing with point detectors, traffic cameras-which have been increasingly deployed on road networks-could cover larger areas and provide more detailed traffic information. In this work, we propose a deep reinforcement learning (DRL) method to explore the potential of traffic video data in improving the efficiency of ramp metering. The proposed method uses traffic video frames as inputs and learns the optimal control strategies directly from the high-dimensional visual inputs. A real-world case study demonstrates that, in comparison with a state-of-the-practice method, the proposed DRL method results in 1) lower travel times in the mainline, 2) shorter vehicle queues at the on-ramp, and 3) higher traffic flows downstream of the merging area. The results suggest that the proposed method is able to extract useful information from the video data for better ramp metering controls.",
        "authors": [
            "Bing Liu",
            "Yu Tang",
            "Yuxiong Ji",
            "Yu Shen",
            "Yuchuan Du"
        ],
        "arxiv_id": "2012.12104v1",
        "url": "http://arxiv.org/abs/2012.12104v1",
        "pdf_link": "https://arxiv.org/pdf/2012.12104v1"
    },
    {
        "title": "Rethink AI-based Power Grid Control: Diving Into Algorithm Design",
        "summary": "Recently, deep reinforcement learning (DRL)-based approach has shown promisein solving complex decision and control problems in power engineering domain.In this paper, we present an in-depth analysis of DRL-based voltage control fromaspects of algorithm selection, state space representation, and reward engineering.To resolve observed issues, we propose a novel imitation learning-based approachto directly map power grid operating points to effective actions without any interimreinforcement learning process. The performance results demonstrate that theproposed approach has strong generalization ability with much less training time.The agent trained by imitation learning is effective and robust to solve voltagecontrol problem and outperforms the former RL agents.",
        "authors": [
            "Xiren Zhou",
            "Siqi Wang",
            "Ruisheng Diao",
            "Desong Bian",
            "Jiahui Duan",
            "Di Shi"
        ],
        "arxiv_id": "2012.13026v1",
        "url": "http://arxiv.org/abs/2012.13026v1",
        "pdf_link": "https://arxiv.org/pdf/2012.13026v1"
    },
    {
        "title": "Fuzzy Commitments Offer Insufficient Protection to Biometric Templates Produced by Deep Learning",
        "summary": "In this work, we study the protection that fuzzy commitments offer when they are applied to facial images, processed by the state of the art deep learning facial recognition systems. We show that while these systems are capable of producing great accuracy, they produce templates of too little entropy. As a result, we present a reconstruction attack that takes a protected template, and reconstructs a facial image. The reconstructed facial images greatly resemble the original ones. In the simplest attack scenario, more than 78% of these reconstructed templates succeed in unlocking an account (when the system is configured to 0.1% FAR). Even in the \"hardest\" settings (in which we take a reconstructed image from one system and use it in a different system, with different feature extraction process) the reconstructed image offers 50 to 120 times higher success rates than the system's FAR.",
        "authors": [
            "Danny Keller",
            "Margarita Osadchy",
            "Orr Dunkelman"
        ],
        "arxiv_id": "2012.13293v1",
        "url": "http://arxiv.org/abs/2012.13293v1",
        "pdf_link": "https://arxiv.org/pdf/2012.13293v1"
    },
    {
        "title": "Generalization in portfolio-based algorithm selection",
        "summary": "Portfolio-based algorithm selection has seen tremendous practical success over the past two decades. This algorithm configuration procedure works by first selecting a portfolio of diverse algorithm parameter settings, and then, on a given problem instance, using an algorithm selector to choose a parameter setting from the portfolio with strong predicted performance. Oftentimes, both the portfolio and the algorithm selector are chosen using a training set of typical problem instances from the application domain at hand. In this paper, we provide the first provable guarantees for portfolio-based algorithm selection. We analyze how large the training set should be to ensure that the resulting algorithm selector's average performance over the training set is close to its future (expected) performance. This involves analyzing three key reasons why these two quantities may diverge: 1) the learning-theoretic complexity of the algorithm selector, 2) the size of the portfolio, and 3) the learning-theoretic complexity of the algorithm's performance as a function of its parameters. We introduce an end-to-end learning-theoretic analysis of the portfolio construction and algorithm selection together. We prove that if the portfolio is large, overfitting is inevitable, even with an extremely simple algorithm selector. With experiments, we illustrate a tradeoff exposed by our theoretical analysis: as we increase the portfolio size, we can hope to include a well-suited parameter setting for every possible problem instance, but it becomes impossible to avoid overfitting.",
        "authors": [
            "Maria-Florina Balcan",
            "Tuomas Sandholm",
            "Ellen Vitercik"
        ],
        "arxiv_id": "2012.13315v1",
        "url": "http://arxiv.org/abs/2012.13315v1",
        "pdf_link": "https://arxiv.org/pdf/2012.13315v1"
    },
    {
        "title": "I like fish, especially dolphins: Addressing Contradictions in Dialogue Modeling",
        "summary": "To quantify how well natural language understanding models can capture consistency in a general conversation, we introduce the DialoguE COntradiction DEtection task (DECODE) and a new conversational dataset containing both human-human and human-bot contradictory dialogues. We then compare a structured utterance-based approach of using pre-trained Transformer models for contradiction detection with the typical unstructured approach. Results reveal that: (i) our newly collected dataset is notably more effective at providing supervision for the dialogue contradiction detection task than existing NLI data including those aimed to cover the dialogue domain; (ii) the structured utterance-based approach is more robust and transferable on both analysis and out-of-distribution dialogues than its unstructured counterpart. We also show that our best contradiction detection model correlates well with human judgments and further provide evidence for its usage in both automatically evaluating and improving the consistency of state-of-the-art generative chatbots.",
        "authors": [
            "Yixin Nie",
            "Mary Williamson",
            "Mohit Bansal",
            "Douwe Kiela",
            "Jason Weston"
        ],
        "arxiv_id": "2012.13391v2",
        "url": "http://arxiv.org/abs/2012.13391v2",
        "pdf_link": "https://arxiv.org/pdf/2012.13391v2"
    },
    {
        "title": "Skeleton-based Approaches based on Machine Vision: A Survey",
        "summary": "Recently, skeleton-based approaches have achieved rapid progress on the basis of great success in skeleton representation. Plenty of researches focus on solving specific problems according to skeleton features. Some skeleton-based approaches have been mentioned in several overviews on object detection as a non-essential part. Nevertheless, there has not been any thorough analysis of skeleton-based approaches attentively. Instead of describing these techniques in terms of theoretical constructs, we devote to summarizing skeleton-based approaches with regard to application fields and given tasks as comprehensively as possible. This paper is conducive to further understanding of skeleton-based application and dealing with particular issues.",
        "authors": [
            "Jie Li",
            "Binglin Li",
            "Min Gao"
        ],
        "arxiv_id": "2012.12447v1",
        "url": "http://arxiv.org/abs/2012.12447v1",
        "pdf_link": "https://arxiv.org/pdf/2012.12447v1"
    },
    {
        "title": "Overview of FPGA deep learning acceleration based on convolutional neural network",
        "summary": "In recent years, deep learning has become more and more mature, and as a commonly used algorithm in deep learning, convolutional neural networks have been widely used in various visual tasks. In the past, research based on deep learning algorithms mainly relied on hardware such as GPUs and CPUs. However, with the increasing development of FPGAs, both field programmable logic gate arrays, it has become the main implementation hardware platform that combines various neural network deep learning algorithms This article is a review article, which mainly introduces the related theories and algorithms of convolution. It summarizes the application scenarios of several existing FPGA technologies based on convolutional neural networks, and mainly introduces the application of accelerators. At the same time, it summarizes some accelerators' under-utilization of logic resources or under-utilization of memory bandwidth, so that they can't get the best performance.",
        "authors": [
            "Simin Liu"
        ],
        "arxiv_id": "2012.12634v1",
        "url": "http://arxiv.org/abs/2012.12634v1",
        "pdf_link": "https://arxiv.org/pdf/2012.12634v1"
    },
    {
        "title": "Modelling Human Routines: Conceptualising Social Practice Theory for Agent-Based Simulation",
        "summary": "Our routines play an important role in a wide range of social challenges such as climate change, disease outbreaks and coordinating staff and patients in a hospital. To use agent-based simulations (ABS) to understand the role of routines in social challenges we need an agent framework that integrates routines. This paper provides the domain-independent Social Practice Agent (SoPrA) framework that satisfies requirements from the literature to simulate our routines. By choosing the appropriate concepts from the literature on agent theory, social psychology and social practice theory we ensure SoPrA correctly depicts current evidence on routines. By creating a consistent, modular and parsimonious framework suitable for multiple domains we enhance the usability of SoPrA. SoPrA provides ABS researchers with a conceptual, formal and computational framework to simulate routines and gain new insights into social systems.",
        "authors": [
            "Rijk Mercuur",
            "Virginia Dignum",
            "Catholijn M. Jonker"
        ],
        "arxiv_id": "2012.11903v1",
        "url": "http://arxiv.org/abs/2012.11903v1",
        "pdf_link": "https://arxiv.org/pdf/2012.11903v1"
    },
    {
        "title": "Dynamic-K Recommendation with Personalized Decision Boundary",
        "summary": "In this paper, we investigate the recommendation task in the most common scenario with implicit feedback (e.g., clicks, purchases). State-of-the-art methods in this direction usually cast the problem as to learn a personalized ranking on a set of items (e.g., webpages, products). The top-N results are then provided to users as recommendations, where the N is usually a fixed number pre-defined by the system according to some heuristic criteria (e.g., page size, screen size). There is one major assumption underlying this fixed-number recommendation scheme, i.e., there are always sufficient relevant items to users' preferences. Unfortunately, this assumption may not always hold in real-world scenarios. In some applications, there might be very limited candidate items to recommend, and some users may have very high relevance requirement in recommendation. In this way, even the top-1 ranked item may not be relevant to a user's preference. Therefore, we argue that it is critical to provide a dynamic-K recommendation, where the K should be different with respect to the candidate item set and the target user. We formulate this dynamic-K recommendation task as a joint learning problem with both ranking and classification objectives. The ranking objective is the same as existing methods, i.e., to create a ranking list of items according to users' interests. The classification objective is unique in this work, which aims to learn a personalized decision boundary to differentiate the relevant items from irrelevant items. Based on these ideas, we extend two state-of-the-art ranking-based recommendation methods, i.e., BPRMF and HRM, to the corresponding dynamic-K versions, namely DK-BPRMF and DK-HRM. Our experimental results on two datasets show that the dynamic-K models are more effective than the original fixed-N recommendation methods.",
        "authors": [
            "Yan Gao",
            "Jiafeng Guo",
            "Yanyan Lan",
            "Huaming Liao"
        ],
        "arxiv_id": "2012.13569v1",
        "url": "http://arxiv.org/abs/2012.13569v1",
        "pdf_link": "https://arxiv.org/pdf/2012.13569v1"
    },
    {
        "title": "Compliance Generation for Privacy Documents under GDPR: A Roadmap for Implementing Automation and Machine Learning",
        "summary": "Most prominent research today addresses compliance with data protection laws through consumer-centric and public-regulatory approaches. We shift this perspective with the Privatech project to focus on corporations and law firms as agents of compliance. To comply with data protection laws, data processors must implement accountability measures to assess and document compliance in relation to both privacy documents and privacy practices. In this paper, we survey, on the one hand, current research on GDPR automation, and on the other hand, the operational challenges corporations face to comply with GDPR, and that may benefit from new forms of automation. We attempt to bridge the gap. We provide a roadmap for compliance assessment and generation by identifying compliance issues, breaking them down into tasks that can be addressed through machine learning and automation, and providing notes about related developments in the Privatech project.",
        "authors": [
            "David Restrepo Amariles",
            "Aurore Clément Troussel",
            "Rajaa El Hamdani"
        ],
        "arxiv_id": "2012.12718v1",
        "url": "http://arxiv.org/abs/2012.12718v1",
        "pdf_link": "https://arxiv.org/pdf/2012.12718v1"
    },
    {
        "title": "PaXNet: Dental Caries Detection in Panoramic X-ray using Ensemble Transfer Learning and Capsule Classifier",
        "summary": "Dental caries is one of the most chronic diseases involving the majority of the population during their lifetime. Caries lesions are typically diagnosed by radiologists relying only on their visual inspection to detect via dental x-rays. In many cases, dental caries is hard to identify using x-rays and can be misinterpreted as shadows due to different reasons such as low image quality. Hence, developing a decision support system for caries detection has been a topic of interest in recent years. Here, we propose an automatic diagnosis system to detect dental caries in Panoramic images for the first time, to the best of authors' knowledge. The proposed model benefits from various pretrained deep learning models through transfer learning to extract relevant features from x-rays and uses a capsule network to draw prediction results. On a dataset of 470 Panoramic images used for features extraction, including 240 labeled images for classification, our model achieved an accuracy score of 86.05\\% on the test set. The obtained score demonstrates acceptable detection performance and an increase in caries detection speed, as long as the challenges of using Panoramic x-rays of real patients are taken into account. Among images with caries lesions in the test set, our model acquired recall scores of 69.44\\% and 90.52\\% for mild and severe ones, confirming the fact that severe caries spots are more straightforward to detect and efficient mild caries detection needs a more robust and larger dataset. Considering the novelty of current research study as using Panoramic images, this work is a step towards developing a fully automated efficient decision support system to assist domain experts.",
        "authors": [
            "Arman Haghanifar",
            "Mahdiyar Molahasani Majdabadi",
            "Seok-Bum Ko"
        ],
        "arxiv_id": "2012.13666v1",
        "url": "http://arxiv.org/abs/2012.13666v1",
        "pdf_link": "https://arxiv.org/pdf/2012.13666v1"
    },
    {
        "title": "Toward Compact Data from Big Data",
        "summary": "Bigdata is a dataset of which size is beyond the ability of handling a valuable raw material that can be refined and distilled into valuable specific insights. Compact data is a method that optimizes the big dataset that gives best assets without handling complex bigdata. The compact dataset contains the maximum knowledge patterns at fine grained level for effective and personalized utilization of bigdata systems without bigdata. The compact data method is a tailor-made design which depends on problem situations. Various compact data techniques have been demonstrated into various data-driven research area in the paper.",
        "authors": [
            " Song-Kyoo",
            " Kim"
        ],
        "arxiv_id": "2012.13677v1",
        "url": "http://arxiv.org/abs/2012.13677v1",
        "pdf_link": "https://arxiv.org/pdf/2012.13677v1"
    },
    {
        "title": "Towards sample-efficient episodic control with DAC-ML",
        "summary": "The sample-inefficiency problem in Artificial Intelligence refers to the inability of current Deep Reinforcement Learning models to optimize action policies within a small number of episodes. Recent studies have tried to overcome this limitation by adding memory systems and architectural biases to improve learning speed, such as in Episodic Reinforcement Learning. However, despite achieving incremental improvements, their performance is still not comparable to how humans learn behavioral policies. In this paper, we capitalize on the design principles of the Distributed Adaptive Control (DAC) theory of mind and brain to build a novel cognitive architecture (DAC-ML) that, by incorporating a hippocampus-inspired sequential memory system, can rapidly converge to effective action policies that maximize reward acquisition in a challenging foraging task.",
        "authors": [
            "Ismael T. Freire",
            "Adrián F. Amil",
            "Vasiliki Vouloutsi",
            "Paul F. M. J. Verschure"
        ],
        "arxiv_id": "2012.13779v1",
        "url": "http://arxiv.org/abs/2012.13779v1",
        "pdf_link": "https://arxiv.org/pdf/2012.13779v1"
    },
    {
        "title": "My Teacher Thinks The World Is Flat! Interpreting Automatic Essay Scoring Mechanism",
        "summary": "Significant progress has been made in deep-learning based Automatic Essay Scoring (AES) systems in the past two decades. However, little research has been put to understand and interpret the black-box nature of these deep-learning based scoring models. Recent work shows that automated scoring systems are prone to even common-sense adversarial samples. Their lack of natural language understanding capability raises questions on the models being actively used by millions of candidates for life-changing decisions. With scoring being a highly multi-modal task, it becomes imperative for scoring models to be validated and tested on all these modalities. We utilize recent advances in interpretability to find the extent to which features such as coherence, content and relevance are important for automated scoring mechanisms and why they are susceptible to adversarial samples. We find that the systems tested consider essays not as a piece of prose having the characteristics of natural flow of speech and grammatical structure, but as `word-soups' where a few words are much more important than the other words. Removing the context surrounding those few important words causes the prose to lose the flow of speech and grammar, however has little impact on the predicted score. We also find that since the models are not semantically grounded with world-knowledge and common sense, adding false facts such as ``the world is flat'' actually increases the score instead of decreasing it.",
        "authors": [
            "Swapnil Parekh",
            "Yaman Kumar Singla",
            "Changyou Chen",
            "Junyi Jessy Li",
            "Rajiv Ratn Shah"
        ],
        "arxiv_id": "2012.13872v1",
        "url": "http://arxiv.org/abs/2012.13872v1",
        "pdf_link": "https://arxiv.org/pdf/2012.13872v1"
    },
    {
        "title": "Neural document expansion for ad-hoc information retrieval",
        "summary": "Recently, Nogueira et al. [2019] proposed a new approach to document expansion based on a neural Seq2Seq model, showing significant improvement on short text retrieval task. However, this approach needs a large amount of in-domain training data. In this paper, we show that this neural document expansion approach can be effectively adapted to standard IR tasks, where labels are scarce and many long documents are present.",
        "authors": [
            "Cheng Tang",
            "Andrew Arnold"
        ],
        "arxiv_id": "2012.14005v1",
        "url": "http://arxiv.org/abs/2012.14005v1",
        "pdf_link": "https://arxiv.org/pdf/2012.14005v1"
    },
    {
        "title": "Devil is in the Edges: Learning Semantic Boundaries from Noisy Annotations",
        "summary": "We tackle the problem of semantic boundary prediction, which aims to identify pixels that belong to object(class) boundaries. We notice that relevant datasets consist of a significant level of label noise, reflecting the fact that precise annotations are laborious to get and thus annotators trade-off quality with efficiency. We aim to learn sharp and precise semantic boundaries by explicitly reasoning about annotation noise during training. We propose a simple new layer and loss that can be used with existing learning-based boundary detectors. Our layer/loss enforces the detector to predict a maximum response along the normal direction at an edge, while also regularizing its direction. We further reason about true object boundaries during training using a level set formulation, which allows the network to learn from misaligned labels in an end-to-end fashion. Experiments show that we improve over the CASENet backbone network by more than 4% in terms of MF(ODS) and 18.61% in terms of AP, outperforming all current state-of-the-art methods including those that deal with alignment. Furthermore, we show that our learned network can be used to significantly improve coarse segmentation labels, lending itself as an efficient way to label new data.",
        "authors": [
            "David Acuna",
            "Amlan Kar",
            "Sanja Fidler"
        ],
        "arxiv_id": "1904.07934v2",
        "url": "http://arxiv.org/abs/1904.07934v2",
        "pdf_link": "https://arxiv.org/pdf/1904.07934v2"
    },
    {
        "title": "How to define co-occurrence in different domains of study?",
        "summary": "This position paper presents a comparative study of co-occurrences. Some similarities and differences in the definition exist depending on the research domain (e.g. linguistics, NLP, computer science). This paper discusses these points, and deals with the methodological aspects in order to identify co-occurrences in a multidisciplinary paradigm.",
        "authors": [
            "Mathieu Roche"
        ],
        "arxiv_id": "1904.08010v1",
        "url": "http://arxiv.org/abs/1904.08010v1",
        "pdf_link": "https://arxiv.org/pdf/1904.08010v1"
    },
    {
        "title": "Decision Making with Machine Learning and ROC Curves",
        "summary": "The Receiver Operating Characteristic (ROC) curve is a representation of the statistical information discovered in binary classification problems and is a key concept in machine learning and data science. This paper studies the statistical properties of ROC curves and its implication on model selection. We analyze the implications of different models of incentive heterogeneity and information asymmetry on the relation between human decisions and the ROC curves. Our theoretical discussion is illustrated in the context of a large data set of pregnancy outcomes and doctor diagnosis from the Pre-Pregnancy Checkups of reproductive age couples in Henan Province provided by the Chinese Ministry of Health.",
        "authors": [
            "Kai Feng",
            "Han Hong",
            "Ke Tang",
            "Jingyuan Wang"
        ],
        "arxiv_id": "1905.02810v1",
        "url": "http://arxiv.org/abs/1905.02810v1",
        "pdf_link": "https://arxiv.org/pdf/1905.02810v1"
    },
    {
        "title": "Feature Selection and Feature Extraction in Pattern Analysis: A Literature Review",
        "summary": "Pattern analysis often requires a pre-processing stage for extracting or selecting features in order to help the classification, prediction, or clustering stage discriminate or represent the data in a better way. The reason for this requirement is that the raw data are complex and difficult to process without extracting or selecting appropriate features beforehand. This paper reviews theory and motivation of different common methods of feature selection and extraction and introduces some of their applications. Some numerical implementations are also shown for these methods. Finally, the methods in feature selection and extraction are compared.",
        "authors": [
            "Benyamin Ghojogh",
            "Maria N. Samad",
            "Sayema Asif Mashhadi",
            "Tania Kapoor",
            "Wahab Ali",
            "Fakhri Karray",
            "Mark Crowley"
        ],
        "arxiv_id": "1905.02845v1",
        "url": "http://arxiv.org/abs/1905.02845v1",
        "pdf_link": "https://arxiv.org/pdf/1905.02845v1"
    },
    {
        "title": "AI-Powered Text Generation for Harmonious Human-Machine Interaction: Current State and Future Directions",
        "summary": "In the last two decades, the landscape of text generation has undergone tremendous changes and is being reshaped by the success of deep learning. New technologies for text generation ranging from template-based methods to neural network-based methods emerged. Meanwhile, the research objectives have also changed from generating smooth and coherent sentences to infusing personalized traits to enrich the diversification of newly generated content. With the rapid development of text generation solutions, one comprehensive survey is urgent to summarize the achievements and track the state of the arts. In this survey paper, we present the general systematical framework, illustrate the widely utilized models and summarize the classic applications of text generation.",
        "authors": [
            "Qiuyun Zhang",
            "Bin Guo",
            "Hao Wang",
            "Yunji Liang",
            "Shaoyang Hao",
            "Zhiwen Yu"
        ],
        "arxiv_id": "1905.01984v1",
        "url": "http://arxiv.org/abs/1905.01984v1",
        "pdf_link": "https://arxiv.org/pdf/1905.01984v1"
    }
]